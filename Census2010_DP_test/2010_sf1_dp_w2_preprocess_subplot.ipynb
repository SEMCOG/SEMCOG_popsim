{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import base64\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess DP and SF1 data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process PD data\n",
    "st = pd.HDFStore('2010dp.h5', complib='zlib', complevel=5 )\n",
    "\n",
    "dp_folder = '2010_dp/'\n",
    "geowidth= [6,2,3,2,3,2,7,1,1,2,3,2,2,5,2,2,5,2,2,6,1,4]\n",
    "geoflds= ['FILEID','STUSAB','SUMLEV','GEOCOMP','CHARITER', 'CIFSN','LOGRECNO',\n",
    "'REGION','DIVISION' ,'STATE' ,'COUNTY' ,'COUNTYCC' ,'COUNTYSC' ,'COUSUB' ,'COUSUBCC' ,'COUSUBSC' , 'PLACE' ,'PLACECC' ,'PLACESC' ,'TRACT' ,'BLKGRP' ,'BLOCK']\n",
    "dfdata = pd.read_fwf(dp_folder + 'migeo2010.dhc', widths =geowidth, names = geoflds, header = None, usecols = range(22))\n",
    "\n",
    "\n",
    "dp_files = {'Segment1_demographicAndHousehold.csv':'mi000012010.dhc',\n",
    "                'Segment2_householdAndGQ.csv':'mi000022010.dhc',\n",
    "                'Segment14_housing.csv':'mi000142010.dhc' }\n",
    "for k in dp_files.keys():               \n",
    "    headers = pd.read_csv(dp_folder + k)\n",
    "    headers = list(headers.columns)[4:]\n",
    "    print(len(headers))\n",
    "    data = pd.read_csv(dp_folder + dp_files[k], header=None, usecols = range(4, len(headers) + 4))\n",
    "    print(data.shape)\n",
    "    data.columns = headers\n",
    "    \n",
    "    dfdata = pd.merge(dfdata, data, left_on = 'LOGRECNO', right_on = 'LOGRECNO', how='left')\n",
    "\n",
    "st['dp_2010']= dfdata\n",
    "st.close()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = pd.HDFStore('2010sf1.h5', complib='zlib', complevel=5)\n",
    "\n",
    "sf1_folder = '2010_sf1_sel/'\n",
    "dfdata = pd.read_csv(sf1_folder + 'GEO_HEADER_SF1.txt', usecols = range(22))\n",
    "\n",
    "sf1_files = ['SF1_00001.txt','SF1_00002.txt','SF1_00003.txt','SF1_00004.txt','SF1_00005.txt','SF1_00044.txt']\n",
    "for f in sf1_files:\n",
    "    print(f)               \n",
    "    data = pd.read_csv(sf1_folder + f)\n",
    "    data.drop(['FILEID','STUSAB','CHARITER','CIFSN'], axis=1,inplace=True)\n",
    "    dfdata = pd.merge(dfdata, data, left_on = 'LOGRECNO', right_on = 'LOGRECNO', how='left')\n",
    "\n",
    "data = pd.read_csv(sf1_folder + 'SF1_00006mod.csv')\n",
    "dfdata = pd.merge(dfdata, data, left_on = 'LOGRECNO', right_on = 'LOGRECNO', how='left')\n",
    "\n",
    "st['sf1_2010'] = dfdata\n",
    "st.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract Table by name and sumlevel"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a lookup table table-> field, so it can be used to extract data by table id\n",
    "# vlist = [col for col in stdp['/dp_2010'].columns if '0' in col ]\n",
    "# tlist = [[col[:-3].replace('0',''), col] for col in vlist]\n",
    "# tlookup = pd.DataFrame(tlist, columns=['table', 'code'])\n",
    "# tlookup = tlookup.set_index('table')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_dif(df1, df2):\n",
    "    \"\"\" generate a percentage based difference table\n",
    "        df1 and df2 have same index and columns\n",
    "        pct_dif set to 0 where df2-df1 equals to 0 \n",
    "        pct_dif rows are removed if cell values are infs (df2-df1>0 but df1 is 0)    \n",
    "    \"\"\"\n",
    "    df_diff = df2.subtract(df1, axis =1)\n",
    "    df_pct_diff = df_diff.div(df1, axis=1) * 100.0\n",
    "    df_pct_diff.update(df_diff[df_diff==0])\n",
    "    df_pct_diff = df_pct_diff.replace([np.inf, -np.inf],np.nan).dropna(axis=0)\n",
    "\n",
    "    return df_pct_diff"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_error_plot(df, ax=None, tle_text=\"\"):\n",
    "    \"\"\"\n",
    "    df generated from pct_diff.describe()\n",
    "    plot shows mean values   \n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    ax.vlines(0, 0, len(df)) #draw the y axis on 0\n",
    "    ax.errorbar(df['mean'], range(len(df.index)), \n",
    "                xerr= [df['mean'] - df['min'], df['max'] - df['mean']], \n",
    "                fmt='ok', ecolor='gray', lw=1, capsize=8)\n",
    "    ax.errorbar(df['mean'], range(len(df.index)), xerr=df['std'], fmt='ok', lw=4)\n",
    "\n",
    "    for (x,y,l) in zip(df['mean'],  range(len(df.index)), round(df['mean'],3)):\n",
    "        ax.text(50, y + 0.1, l, size=20)\n",
    "\n",
    "    ax.set_title( tle_text + ' PCT ERRORS')\n",
    "    ax.set_yticks(range(len(df.index)))\n",
    "    ax.set_yticklabels(df.index)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_plots(lst_dfs):\n",
    "    \"\"\"\n",
    "    subplots with dimension 1 x X (X is the number of df being compared)\n",
    "    df should have name\n",
    "    \"\"\"\n",
    "    sns.set(font_scale=2)   \n",
    "    fig, axs = plt.subplots(1, len(lst_dfs), sharex=True, sharey=True, \n",
    "                            figsize=(30, max(5, len(lst_dfs[0]))), \n",
    "                            gridspec_kw={'hspace': 0, 'wspace': 0.02})\n",
    "    c=0\n",
    "    for df in lst_dfs:\n",
    "        sub_error_plot(df, axs[c], \" \".join(df.name.split(\"_\")))\n",
    "        c += 1\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdp = pd.HDFStore('2010dp.h5', 'r' )\n",
    "stsf1 = pd.HDFStore('2010sf1.h5', 'r' )"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build an field name lookup table, so the plot can use name instead of field code\n",
    "sf1_folder = '2010_sf1_sel/'\n",
    "df_lookup = pd.read_excel(sf1_folder + 'SelectVariablesToCompare.xlsx')\n",
    "df_lookup.dropna(axis =0, inplace = True)\n",
    "tbl_lookup = df_lookup[['TABLE NUMBER', 'FIELD CODE']].set_index('TABLE NUMBER')\n",
    "name_lookup = df_lookup[['FIELD CODE', 'FIELD NAME']].set_index('FIELD CODE')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_levels = {\"PLACE\": ['STATE', 'COUNTY', 'COUSUB','PLACE'],\n",
    "            \"TRACT\":['STATE', 'COUNTY', 'TRACT'],\n",
    "            \"BLKGRP\":['STATE', 'COUNTY', 'TRACT', 'BLKGRP'] }\n",
    "sum_levels = {\"PLACE\":70, \"TRACT\":140, \"BLKGRP\":150}\n",
    "\n",
    "dp_2010 = stdp['/dp_2010'].loc[stdp['/dp_2010'].SUMLEV.isin(list(sum_levels.values()))]\n",
    "sf1_2010 = stsf1['/sf1_2010'].loc[stsf1['/sf1_2010'].SUMLEV.isin(list(sum_levels.values()))]\n",
    "\n",
    "    \n",
    "dfdifs={}\n",
    "dfps={}\n",
    "for t in df_lookup['TABLE NUMBER'].unique():\n",
    "    print('table:', t)\n",
    "    vcodes = list(tbl_lookup.loc[[t]]['FIELD CODE'])\n",
    "\n",
    "    for lev, geoids in geo_levels.items():\n",
    "        \n",
    "        dpdata = dp_2010.loc[dp_2010.SUMLEV == sum_levels[lev], geoids + vcodes ]\n",
    "        sf1data = sf1_2010.loc[sf1_2010.SUMLEV == sum_levels[lev], geoids + vcodes]\n",
    "        dpdata =  dpdata.set_index(geoids)\n",
    "        sf1data =  sf1data.set_index(geoids)\n",
    "\n",
    "        dfdifs[(t, lev)] = pct_dif(sf1data, dpdata)#keep difference tables for other uses\n",
    "        dfp = dfdifs[(t, lev)].describe().T.sort_index(axis = 0, ascending = False)\n",
    "        dfp.index=name_lookup.loc[dfp.index, 'FIELD NAME']\n",
    "        dfps[(t, lev)] = dfp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in df_lookup['TABLE NUMBER'].unique():\n",
    "    print('table ', t )\n",
    "    lst_dfs = []\n",
    "    for geo in geo_levels.keys():\n",
    "        df = dfps[(t, geo)]\n",
    "        df.name = t +\"_\" + geo\n",
    "        lst_dfs.append(df)\n",
    "    fig= compare_plots(lst_dfs)\n",
    "    fig.savefig('plots/' + t + '_error_plot.png', bbox_inches = \"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}