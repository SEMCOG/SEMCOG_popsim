{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 2015 SEMCOG Urbansim base year demographic data to ABM test inputs\n",
    "\n",
    "## ABM HHs: HHID, TAZ, *TYPE, HINCP, *ADJINC, NP, *HHT, VEH (* new variables)\n",
    "## ABM Persons: HHID, PERID, AGEP, SEX, *ESR, *WKHP, *WKW, *SCHG, *MIL\n",
    "## note. both ABM HH and Person tables include GQ HH and Person records\n",
    "\n",
    "## see document for the details of task purpose and methodology\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "from pandas_profiling import ProfileReport\n",
    "from datetime import date\n",
    "import random\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input setup\n",
    "infolder = 'inputs'\n",
    "outfolder = 'outputs'\n",
    "hdf_model = 'all_semcog_data_02-02-18.h5' # model base year, final version\n",
    "hdf_syn = 'starter6_20171019-1526.h5' # synthesized results\n",
    "tract_puma = 'https://www2.census.gov/geo/docs/maps-data/data/rel/2010_Census_Tract_to_2010_PUMA.txt'\n",
    "\n",
    "pums_hhs = 'ss15hmi.csv'\n",
    "pums_pps = 'ss15pmi.csv'\n",
    "newhh_vars = ['TYPE', 'HINCP', 'ADJINC', 'HHT']\n",
    "newperson_vars = ['ESR', 'WKHP', 'WKW', 'SCHG', 'MIL']\n",
    "\n",
    "#output files\n",
    "outhhs = 'abm_hhs_{}.csv'.format(str(date.today()))\n",
    "outpersons = 'abm_persons_{}.csv'.format(str(date.today()))\n",
    "outgq = 'abm_gq_{}.csv'.format(str(date.today()))\n",
    "outgq_hhs = 'abm_gq_hhs_{}.csv'.format(str(date.today()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stm = pd.HDFStore(os.path.join(infolder, hdf_model), 'r') \n",
    "sts = pd.HDFStore(os.path.join(infolder, hdf_syn), 'r') \n",
    "\n",
    "#1. tract to puma for MI\n",
    "df_tract_puma = pd.read_csv(tract_puma)\n",
    "df_tract_puma = df_tract_puma.loc[df_tract_puma.STATEFP == 26]\n",
    "\n",
    "#2 building with other geos\n",
    "bldgeos = pd.merge(stm['buildings'][['parcel_id', 'b_zone_id']], \n",
    "                    stm['parcels'][['census_bg_id', 'county_id']], \n",
    "                    left_on = 'parcel_id', right_index = True, how = 'left')\n",
    "bldgeos['tract'] = bldgeos.census_bg_id//10\n",
    "bldgeos = pd.merge(bldgeos.reset_index(), df_tract_puma[['COUNTYFP','TRACTCE','PUMA5CE']], \n",
    "                            left_on = ['county_id', 'tract'], right_on = ['COUNTYFP','TRACTCE'], \n",
    "                            how='left').set_index('building_id')\n",
    "bldgeos = bldgeos.rename(columns = {'b_zone_id': 'zone_id'})\n",
    "bldgeos = bldgeos.fillna(0).astype(int)                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_index(df1, df2, keycols):\n",
    "    \"\"\" for every record in df1, identify and sample a matching record from df2\n",
    "        df1: table to search (iterate)\n",
    "        df2: table to sample from (query table)\n",
    "        keycols: list of column names to be used as matching key\n",
    "        df1 ands df2 must have valid index name. final table will have df2 index column joined to df1\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "\n",
    "    v1, v2 = df1.index.name, df2.index.name\n",
    "    assert((type(v1) == str) & (type(v2) == str) == True)  # make sure both index names exist\n",
    "    print ('matching indices: ', 'df1/'+ v1, 'df2/'+ v2)\n",
    "    df1 = df1.reset_index().set_index([v1] + keycols).sort_index() \n",
    "    df2 = df2.reset_index()\n",
    "    qrylst = df1.index # assign searching sequence\n",
    "    tcounts = len(qrylst)\n",
    "\n",
    "    dfsample = []\n",
    "    while (len(qrylst) > 0) and (len(keycols) > 0):\n",
    "        df2 = df2.set_index(keycols).sort_index()\n",
    "        qrylst_remain = []\n",
    "        for k in qrylst:\n",
    "            try:\n",
    "                dfsample.append([k[0], df2.loc[k[1:]].sample(1)[v2].values[0]])\n",
    "                if len(dfsample) % 1000 == 0: #show progress\n",
    "                    print ('\\rworking [%1.1f%%]' % (len(dfsample)/tcounts * 100), end =\"\")\n",
    "            except:\n",
    "                qrylst_remain.append(k[:-1])\n",
    "        qrylst = qrylst_remain\n",
    "        keycols = keycols[:-1]\n",
    "        print('\\nkey = ', keycols, '| total successfully sampled', len(dfsample), '| remain', len(qrylst))\n",
    "        df2 = df2.reset_index()\n",
    "    if len(qrylst_remain) > 0:  print(qrylst_remain)\n",
    "    df1 = pd.merge(df1.reset_index(), pd.DataFrame(dfsample, columns = [v1, v2]), \n",
    "                                        left_on = v1, right_on = v1, how = 'left' ).set_index(v1)\n",
    "    print (\"total time: %1.1f seconds\" % (time.time()-t0))\n",
    "\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample matching PUMS samples for additional HHs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process model HHs, attach bg_id, zone_id, county and PUMA\n",
    "modhh = stm['households']\n",
    "modhh.fillna(0, inplace=True)\n",
    "modhh = pd.merge(modhh, bldgeos, left_on = 'building_id', right_index = True, how = 'left')\n",
    "print('\\nindex name:  \\t', modhh.index.name, '\\ncolumns:   \\t', modhh.columns.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process synthesized HHS, attach county and PUMA\n",
    "synhh = sts['sim_households']\n",
    "synhh.fillna(0, inplace=True)\n",
    "synhh.tract = synhh.tract.astype(int)\n",
    "synhh['county_id'] = synhh.index.values//10000000\n",
    "synhh = pd.merge(synhh.reset_index(), df_tract_puma[['COUNTYFP','TRACTCE','PUMA5CE']], \n",
    "                            left_on = ['county', 'tract'], right_on = ['COUNTYFP','TRACTCE'],                                            how='left').set_index('household_id')\n",
    "print('\\nindex name: \\t', synhh.index.name, '\\ncolumns: \\t', synhh.columns.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enlist added HHs, that is all hhs in model inputs but not in original synthesis dataset( they were added in post-process)\n",
    "modhh_match = modhh.loc[modhh.index.isin(synhh.index)]\n",
    "modhh_added = modhh.loc[~modhh.index.isin(synhh.index)]\n",
    "print(len(modhh), len(modhh_match) + len(modhh_added), len(modhh_match), len(modhh_added))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keycols = ['income', 'race_id', 'age_of_head','cars', 'county_id','PUMA5CE']\n",
    "\n",
    "#process key col values for better matching process\n",
    "for df in [synhh, modhh_added]: \n",
    "    df[keycols] = df[keycols].fillna(0)\n",
    "    df[keycols] = df[keycols].round(0)\n",
    "    df[keycols] = df[keycols].astype(int)\n",
    "    print (df[keycols].head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modhh_added = find_matching_index(modhh_added, synhh.reset_index().set_index('serialno'), keycols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = synhh.loc[synhh.index.isin(modhh.index)]\n",
    "modhh.loc[match.index, 'serialno'] = match['serialno']\n",
    "modhh.loc[modhh_added.index, 'serialno'] = modhh_added['serialno']\n",
    "modhh.loc[modhh.serialno.isnull()] #verify if there's still added HHs with missing serialno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read HHT from 2015 PUMS dataset and attach them to model HHs\n",
    "pumshhs = pd.read_csv(os.path.join(infolder, pums_hhs), usecols=['SERIALNO'] + newhh_vars)\n",
    "modhh = pd.merge(modhh.reset_index(), pumshhs, left_on='serialno', \n",
    "                    right_on='SERIALNO', how='left').set_index('household_id')\n",
    "modhh.drop(['income', 'workers'], axis = 1, inplace = True) #drop income and workers since they have different meaning in ABM\n",
    "print('save draft HHs to ' + os.path.join(outfolder, outhhs.replace('.csv', '_raw.csv')))\n",
    "modhh.to_csv(os.path.join(outfolder, outhhs.replace('.csv', '_raw.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modhh.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modhh[set(modhh.columns) - set(['income','workers'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample matching PUMS samples for additional persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add extra attributes from PUMS data to model persons\n",
    "pumspps = pd.read_csv(os.path.join(infolder, pums_pps), usecols=['SERIALNO', 'SPORDER'] + newperson_vars)\n",
    "\n",
    "modpp = stm['persons']\n",
    "modpp_cols = modpp.columns\n",
    "modpp = pd.merge(modpp.reset_index(), modhh[['serialno', 'county_id']], left_on='household_id',                                                    right_index=True, how='left').set_index('person_id')\n",
    "modpp = pd.merge(modpp.reset_index(), pumspps, left_on=['serialno', 'member_id'], \n",
    "                                        right_on=['SERIALNO', 'SPORDER'], how='left').set_index('person_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modpp_added = modpp.loc[modpp.SERIALNO.isnull() ] #persons without proper HH id after joining(new person only in model inputs) \n",
    "modpp_match = modpp.loc[~modpp.SERIALNO.isnull() ] #persons in original synthesis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keycols = ['county_id', 'worker', 'sex',  'race_id', 'age']\n",
    "newid = modpp_added.index.name + '_add'\n",
    "modpp_added.index.name = newid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modpp_added = find_matching_index(modpp_added, modpp_match, keycols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modpp_added.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modpp_added = modpp_added.reset_index().set_index('person_id')\n",
    "modpp_added[newperson_vars] = modpp_match[newperson_vars]\n",
    "modpp_added = modpp_added.set_index(newid)\n",
    "modpp.loc[modpp_added.index, newperson_vars] = modpp_added[newperson_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('save draft persons to ' + os.path.join(outfolder, outpersons.replace('.csv', '_raw.csv')))\n",
    "modpp.to_csv(os.path.join(outfolder, outpersons.replace('.csv', '_raw.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modpp.loc[modpp.SERIALNO.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process group quarter population#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get county and PUMA to GQ pop\n",
    "modgq = pd.merge(stm['/group_quarters'], bldgeos, left_on = 'building_id', right_index=True, how='left')\n",
    "print(modgq.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode GQ type: 401 instituational (military), \n",
    "# 401\toif\tOther Institutional\n",
    "# 501\tcsh\tCollege/Student Housing\n",
    "# 701\tonf\tOther NonInstitutional\n",
    "# 789\tHL\tHomeless Population\n",
    "\n",
    "modgq = modgq.loc[modgq.gq_code >= 401]\n",
    "modgq['TYPE'] = 3\n",
    "modgq.loc[modgq.gq_code == 401, 'TYPE'] = 2 \n",
    "modgq.rename(columns={'PUMA5CE':'PUMA'}, inplace=True)\n",
    "modgq['PUMA']= modgq['PUMA'].fillna(0).astype(int)\n",
    "#modgq with TYPE, county_id, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pumshhs = pd.read_csv('2015_synthpop_inputs/ss15hmi.csv', usecols=['SERIALNO', 'TYPE','NP', 'PUMA00','PUMA10'])\n",
    "\n",
    "#2. PUMA 2000 to 2010 look up (one on one)\n",
    "puma_00_10 = pd.read_excel('PUMA2000_PUMA2010_crosswalk.xls')[['State10','PUMA00', 'PUMA10', \n",
    "                                                                            'pPUMA00_Pop10']]\n",
    "puma_00_10 = puma_00_10.loc[puma_00_10.State10 == 26].sort_values(['PUMA00', 'pPUMA00_Pop10'],                                                                                          ascending=False)\n",
    "puma_00_10.drop_duplicates(subset ='PUMA00', keep='first', inplace= True)\n",
    "puma_00_10= puma_00_10.set_index('PUMA00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get PUMA id, filter by GQ pop and valid PUMAs\n",
    "pumspps = pd.read_csv(os.path.join(infolder, pums_pps), usecols=['SERIALNO','SPORDER', 'RELP', 'AGEP', 'RAC1P', 'HISP','SEX', 'SCHG', 'WKHP', 'WKW', 'ESR','MIL', 'PUMA00','PUMA10'])\n",
    "\n",
    "pumspps = pumspps.set_index('PUMA00')\n",
    "pumspps.update(puma_00_10[['PUMA10']])\n",
    "pumspps =  pumspps.rename(columns={'PUMA10': 'PUMA'}).reset_index()\n",
    "pumspps = pumspps.loc[pumspps.RELP.isin([16,17]) & pumspps.PUMA.isin(modgq.PUMA.unique())]\n",
    "pumspps = pumspps.set_index('SERIALNO')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare matching variables for PUMS samples\n",
    "pumspps['TYPE'] = 3\n",
    "pumspps.loc[pumspps.RELP ==16, 'TYPE'] = 2\n",
    "\n",
    "pumspps['race_id'] = pumspps.RAC1P \n",
    "pumspps.loc[pumspps.RAC1P > 2, 'race_id'] = 4\n",
    "pumspps.loc[pumspps.HISP > 1, 'race_id'] = 3\n",
    "\n",
    "pumspps['age'] = pumspps.AGEP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modgq = find_matching_index(modgq, pumspps, ['TYPE', 'race_id', 'age', 'PUMA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modgq = pd.merge(modgq.reset_index(), pumspps, left_on = 'SERIALNO', right_index = True, how = 'left',                                                      suffixes = ('', '_y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modgq.rename(columns = {\"RELP\": \"relate\", \"SEX\":\"sex\", \"SPORDER\": \"member_id\"}, inplace = True)\n",
    "\n",
    "modgq['person_id'] = range(2_000_000_000, 2_000_000_000 + len(modgq))\n",
    "modgq['household_id'] = modgq['person_id']\n",
    "modgq = modgq.set_index('person_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export GQ persons\n",
    "print('save draft GQ persons to ' + os.path.join(outfolder, outgq.replace('.csv', '_raw.csv')))\n",
    "modgq.to_csv(os.path.join(outfolder, outgq.replace('.csv', '_raw.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modgq.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process group quarter households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covnert GQ persons to GQ HHs \n",
    "pumshhs = pd.read_csv(os.path.join(infolder, pums_hhs), usecols=['SERIALNO','VEH', 'NP','NOC'] + newhh_vars)\n",
    "pumshhs = pumshhs.loc[pumshhs.TYPE > 1]\n",
    "modgq_hhs = pd.merge(modgq, pumshhs, left_on = 'SERIALNO', right_on = 'SERIALNO', how = 'left', suffixes = ('', '_y') )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename variables\n",
    "modgq_hhs.rename(columns = {'age':'age_of_head', \n",
    "                            'VEH': 'cars', \n",
    "                            'NOC': 'children',\n",
    "                            'NP': 'persons'}, inplace = True)\n",
    "modgq_hhs = modgq_hhs.set_index('household_id')                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modgq_hhs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modgq_hhs.to_csv(os.path.join(outfolder, outgq_hhs.replace('.csv', '_raw.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(stm['households'].columns) - set(['income', 'workers'])) + newhh_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select needed variables for final outputs\n",
    "hset = list(set(stm['households'].columns) - set(['income', 'workers'])) + newhh_vars\n",
    "pset = list(set(stm['persons'].columns) - set(['worker'])) + newperson_vars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final households and persons \n",
    "pd.concat([modhh[hset], modgq_hhs[hset]]).to_csv(os.path.join(outfolder, outhhs))\n",
    "pd.concat([modpp[pset], modgq[pset]]).to_csv(os.path.join(outfolder, outpersons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional compile ABM variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update person and household worker with new definition ESR in [1,2,4,5] \n",
    "modpp.loc[modpp.ESR.isin([1,2,4,5]), 'worker'] = 1\n",
    "modhh['workers'] = 0 #reset the values, cannot keep them\n",
    "modhh['workers'] = modpp.groupby('household_id').worker.sum()\n",
    "\n",
    "modpp['pemploy'] = 2 #part time\n",
    "modpp.loc[modpp.age < 16, 'pemploy'] = 4  #under16\n",
    "modpp.loc[(modpp.age >= 16) & (modpp.ESR.isin([3,6])) , 'pemploy'] = 3 #not employed\n",
    "modpp.loc[(modpp.age >= 16) & (~modpp.ESR.isin([3,6])) & (modpp.WKHP >= 35) & (modpp.WKW.isin([1,2,3,4])), 'pemploy'] = 1  # full time\n",
    "\n",
    "modpp.loc[(modpp.age >= 16) & (modpp.pemploy == 1), 'pstudent'] = 3 # not attending school\n",
    "modpp.loc[(modpp.age < 16) & (modpp.pemploy == 1), 'pstudent'] = 1 # high school or lower\n",
    "modpp.loc[modpp.SCHG.isnull() & (modpp.age >= 16), 'pstudent'] = 3\n",
    "modpp.loc[modpp.SCHG.isnull() & (modpp.age < 16), 'pstudent'] = 1\n",
    "modpp.loc[(modpp.pemploy != 1) & (modpp.SCHG >= 15) & (modpp.age >= 16), 'pstudent'] = 2# college or higher\n",
    "modpp.loc[(modpp.pemploy != 1) & (modpp.SCHG >= 15) & (modpp.age < 16), 'pstudent'] = 1\n",
    "modpp.loc[(modpp.pemploy != 1) & (modpp.SCHG.isin(range(1,15))) & (modpp.age <= 19), 'pstudent'] = 1\n",
    "modpp.loc[(modpp.pemploy != 1) & (modpp.SCHG.isin(range(1,15))) & (modpp.age > 19), 'pstudent'] = 2\n",
    "\n",
    "modpp.loc[modpp.pemploy == 1, 'ptype'] = 1\n",
    "modpp.loc[(modpp.pemploy == 2) & (modpp.pstudent == 3), 'ptype'] = 2\n",
    "modpp.loc[(modpp.age >= 65) & (modpp.pemploy.isin([3,4])) & (modpp.pstudent == 3), \n",
    "            'ptype'] = 5\n",
    "modpp.loc[(modpp.age < 6) & (modpp.pemploy.isin([3,4])) & (modpp.pstudent == 3), \n",
    "            'ptype'] = 8\n",
    "modpp.loc[((modpp.age >= 6) & (modpp.age <= 64)) & (modpp.pemploy.isin([3,4])) &                           (modpp.pstudent == 3) , 'ptype'] = 4\n",
    "modpp.loc[(modpp.pemploy.isin([2, 3, 4])) & (modpp.pstudent == 2) , 'ptype'] = 3\n",
    "modpp.loc[(modpp.age < 6) & (modpp.pemploy.isin([2,3,4])) & (modpp.pstudent == 1), \n",
    "            'ptype'] = 8\n",
    "modpp.loc[(modpp.age >= 16) & (modpp.pemploy.isin([2,3,4])) & (modpp.pstudent == 1), \n",
    "            'ptype'] = 6\n",
    "modpp.loc[((modpp.age >= 6) & (modpp.age < 16)) & (modpp.pemploy.isin([2,3,4])) &                       (modpp.pstudent == 1) , 'ptype'] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSG notes on ABM data inputs\n",
    "\n",
    "# Household attributes:\n",
    "# 1.\tHworkers: Yes, this is number of workers in the household based on each member’s Employment Status Recode (ESR). ESR is defined in PUMS as follows:\n",
    "# Members with ESR as 1, 2, 4 and 5 are counted as workers\n",
    "# 2.\tHHT: Yes, this is the original PUMS field – Household/family type\n",
    "\n",
    "\n",
    "# Person Type (ptype):\n",
    "# 1.\tThe ptype code is defined using the following PUMS person-level variables:\n",
    "# a.\tESR: Employment Status Recode (ESR)\n",
    "# b.\tWKHP: Usual hours worked per week past 12 months\n",
    "# c.\tWKW: Weeks worked during past 12 months\n",
    "# d.\tSCHG: Grade level attending\n",
    "# e.\tAGEP: Age\n",
    "\n",
    "# 2.\tThe person type is derived from person’s age, employment status (pemploy) and student status (pstudent).\n",
    "# 3.\tThe employment status is derived from ESR, WKHP, WKW and Age\n",
    "# 4.\tThe student status is derived from SCHG, Age and employment status\n",
    "\n",
    "# As long as we have ESR, WKHP, WKW, SCHG and AGEP in the person file, employment status, student status and person type can be derived.\n",
    "\n",
    "# We have documented the person type coding process for ODOT. Please follow this link for a  detailed description of person type coding logic: https://github.com/RSGInc/SOABM/wiki/Person-Type-Coding-in-SOABM\n",
    "\n",
    "# https://github.com/RSGInc/SOABM/wiki/Person-Type-Coding-in-SOABM\n",
    "# PUMS variable definitions( year unkown * different from 2015 definitions see below)\n",
    "# Employment status recode ESR\n",
    "#     b .N/A (less than 16 years old)\n",
    "#     1 .Civilian employed, at work\n",
    "#     2 .Civilian employed, with a job but not at work\n",
    "#     3 .Unemployed\n",
    "#     4 .Armed forces, at work\n",
    "#     5 .Armed forces, with a job but not at work\n",
    "#     6 .Not in labor force\n",
    "\n",
    "# WKHP\n",
    "# Usual hours worked per week past 12 months\n",
    "#     bb .N/A (less than 16 years old/did not work during the past 12 months)\n",
    "#     01..98 .1 to 98 usual hours\n",
    "#     99 .99 or more usual hours\n",
    "\n",
    "# WKW\n",
    "# Weeks worked during past 12 months\n",
    "#     b .N/A (less than 16 years old/did not work during the past 12 months)\n",
    "#     1 .50 to 52 weeks\n",
    "#     2 .48 to 49 weeks\n",
    "#     3 .40 to 47 weeks\n",
    "#     4 .27 to 39 weeks\n",
    "#     5 .14 to 26 weeks\n",
    "#     6 .13 weeks or less\n",
    "\n",
    "# ========================================================\n",
    "# SCHG https://github.com/RSGInc/SOABM/wiki/Person-Type-Coding-in-SOABM\n",
    "# Grade level attending\n",
    "#     b .N/A (not attending school)\n",
    "#     1 .Nursery school/preschool\n",
    "#     2 .Kindergarten\n",
    "#     3 .Grade 1 to grade 4\n",
    "#     4 .Grade 5 to grade 8\n",
    "#     5 .Grade 9 to grade 12\n",
    "#     6 .College undergraduate\n",
    "#     7 .Graduate or professional school\n",
    "#     AGEP\n",
    "#     Age\n",
    "#     00 .Under 1 year\n",
    "#     01..99 .1 to 99 years (Top-coded***)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SCHG (2015 PUMS variable codes, SEMCOG model base year data)\n",
    "# Grade level attending\n",
    "#     bb .N/A (not attending school)\n",
    "#     01 .Nursery school/preschool\n",
    "#     02 .Kindergarten\n",
    "#     03 .Grade 1\n",
    "#     04 .Grade 2\n",
    "#     05 .Grade 3\n",
    "#     06 .Grade 4\n",
    "#     07 .Grade 5\n",
    "#     08 .Grade 6\n",
    "#     09 .Grade 7\n",
    "#     10 .Grade 8\n",
    "#     11 .Grade 9\n",
    "#     12 .Grade 10\n",
    "#     13 .Grade 11\n",
    "#     14 .Grade 12\n",
    "#     15 .College undergraduate years (freshman to senior)\n",
    "#     16 .Graduate or professional school beyond a bachelor's degree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python37464bitbaseconda6f9e6f4ac8a84988b167991f607929ce",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}