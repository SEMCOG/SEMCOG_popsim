{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 2015 SEMCOG Urbansim base year demographic data to ABM test inputs\n",
    "\n",
    "## ABM HHs: HHID, TAZ, *TYPE, HINCP, *ADJINC, NP, *HHT, VEH (* new variables)\n",
    "## ABM Persons: HHID, PERID, AGEP, SEX, *ESR, *WKHP, *WKW, *SCHG, *MIL, *PINCP(for GQ)\n",
    "## note. both ABM HH and Person tables include GQ HH and Person records\n",
    "\n",
    "## see document for the details of task purpose and methodology\n",
    "\n",
    "# 04-22-2020\n",
    "# fix member id: no duplicates in same HH\n",
    "# document: provide detailed data dictionary\n",
    "# household id: consider shorter int number(in the future)\n",
    "# NAs: Set all NAs to -9\n",
    "# HHT: for GQ records is set to 0\n",
    "# HINCP: Use PINCP (personal income) for GQ records instead of  (household income). \n",
    "# HINCP adjustment: this dataset uses original HINCP and PINCP from PUMS, so not adjustment was implemented. The \"income\" variable in official 2015 model base year was adjusted. \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "from pandas_profiling import ProfileReport\n",
    "from datetime import date\n",
    "import random\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input setup\n",
    "# all data under ABM/test_data_012020/\n",
    "infolder = 'inputs'\n",
    "outfolder = 'outputs'\n",
    "hdf_model = 'all_semcog_data_02-02-18.h5' # model base year, final version\n",
    "hdf_syn = 'starter6_20171019-1526.h5' # synthesized results\n",
    "tract_puma = 'https://www2.census.gov/geo/docs/maps-data/data/rel/2010_Census_Tract_to_2010_PUMA.txt'\n",
    "\n",
    "pums_hhs = 'ss15hmi.csv'\n",
    "pums_pps = 'ss15pmi.csv'\n",
    "newhh_vars = ['TYPE', 'HINCP', 'ADJINC', 'HHT']\n",
    "newperson_vars = ['ESR', 'WKHP', 'WKW', 'SCHG', 'MIL']\n",
    "na_value = -9 #for fillna\n",
    "\n",
    "#output files\n",
    "outhhs = 'abm_hhs_{}.csv'.format(str(date.today()))\n",
    "outpersons = 'abm_persons_{}.csv'.format(str(date.today()))\n",
    "outgq = 'abm_gq_{}.csv'.format(str(date.today()))\n",
    "outgq_hhs = 'abm_gq_hhs_{}.csv'.format(str(date.today()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stm = pd.HDFStore(os.path.join(infolder, hdf_model), 'r') # model inputs\n",
    "sts = pd.HDFStore(os.path.join(infolder, hdf_syn), 'r') #original synthesized output, with matching household ID to model inputs but doesn't include adjusted/created HHs and Persons\n",
    "\n",
    "#1. tract to puma cross-walk for MI\n",
    "df_tract_puma = pd.read_csv(tract_puma)\n",
    "df_tract_puma = df_tract_puma.loc[df_tract_puma.STATEFP == 26]\n",
    "\n",
    "#2 associate building with other geographic units: county, tract, PUMA, etc\n",
    "bldgeos = pd.merge(stm['buildings'][['parcel_id', 'b_zone_id']], stm['parcels'][['census_bg_id', 'county_id']], \n",
    "            left_on = 'parcel_id', right_index = True, how = 'left')\n",
    "bldgeos['tract'] = bldgeos.census_bg_id//10\n",
    "bldgeos = pd.merge(bldgeos.reset_index(), df_tract_puma[['COUNTYFP','TRACTCE','PUMA5CE']], \n",
    "           left_on = ['county_id', 'tract'], right_on = ['COUNTYFP','TRACTCE'], how='left').set_index('building_id')\n",
    "bldgeos = bldgeos.rename(columns = {'b_zone_id': 'zone_id'})\n",
    "bldgeos = bldgeos.fillna(na_value).astype(int)                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_index(df1, df2, keycols):\n",
    "    \"\"\" for every record in df1, identify and sample a matching record from df2\n",
    "        df1: table to search (iterate rows)\n",
    "        df2: table to sample from (query and sample)\n",
    "        keycols: list of columns to be used as matching key, both df1 and df2 must have same keycols \n",
    "        df1 ands df2 must have valid index name. final table will have df2 index column joined to df1\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "\n",
    "    v1, v2 = df1.index.name, df2.index.name\n",
    "    assert((type(v1) == str) & (type(v2) == str) == True)  # make sure both index names exist\n",
    "    print ('matching indices: df1:{} -- df1:{}'.format(v1, v2))\n",
    "    df1 = df1.reset_index().set_index([v1] + keycols).sort_index() \n",
    "    qrylst = df1.index # assign searching sequence\n",
    "    tcounts = len(qrylst)\n",
    "\n",
    "    dfsample = []\n",
    "    while (len(qrylst) > 0) and (len(keycols) > 0):\n",
    "        df2 = df2.reset_index()\n",
    "        df2 = df2.set_index(keycols).sort_index() #set index for query\n",
    "        qrylst_remain = []  #if query cannot find a matching sample, store the line with 1 less key in this list\n",
    "        for k in qrylst:\n",
    "            try:\n",
    "                dfsample.append([k[0], df2.loc[k[1:]].sample(1)[v2].values[0]])\n",
    "                if len(dfsample) % 1000 == 0: #show progress\n",
    "                    print ('\\rworking [%1.1f%%]' % (len(dfsample)/tcounts * 100), end =\"\")\n",
    "            except:\n",
    "                qrylst_remain.append(k[:-1]) # store with 1 less key\n",
    "        qrylst = qrylst_remain\n",
    "        keycols = keycols[:-1] #drop one key\n",
    "        print('\\nkey = ', keycols, '| total successfully matched: ', len(dfsample), '| unmatched: ', len(qrylst))\n",
    "        \n",
    "    if len(qrylst_remain) > 0:  print(\"Done but still have unmatched records! \", qrylst_remain)\n",
    "    df1 = pd.merge(df1.reset_index(), pd.DataFrame(dfsample, columns = [v1, v2]), \n",
    "                                        left_on = v1, right_on = v1, how = 'left' ).set_index(v1)\n",
    "    print (\"total time: %1.1f seconds\" % (time.time()-t0))\n",
    "\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match PUMS samples for additional HHs in model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process model HHs, attach bg_id, zone_id, county and PUMA\n",
    "modhh = stm['households'].fillna(na_value)\n",
    "modhh = pd.merge(modhh, bldgeos, left_on = 'building_id', right_index = True, how = 'left')\n",
    "print('\\nmodel index:  \\t', modhh.index.name, '\\ncolumns:   \\t', modhh.columns.values)\n",
    "\n",
    "#process synthesized HHS, attach county and PUMA\n",
    "synhh = sts['sim_households'].fillna(na_value)\n",
    "synhh.tract = synhh.tract.astype(int)\n",
    "synhh['county_id'] = synhh.index.values//10000000\n",
    "synhh = pd.merge(synhh.reset_index(), df_tract_puma[['COUNTYFP','TRACTCE','PUMA5CE']], \n",
    "                            left_on = ['county', 'tract'], right_on = ['COUNTYFP','TRACTCE'],                                                      how='left').set_index('household_id')\n",
    "print('\\nsynth index: \\t', synhh.index.name, '\\ncolumns: \\t', synhh.columns.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enlist added HHs, that is all hhs in model inputs but not in original synthesis dataset( they were added in post-process)\n",
    "modhh_match = modhh.loc[modhh.index.isin(synhh.index)]\n",
    "modhh_added = modhh.loc[~modhh.index.isin(synhh.index)]\n",
    "assert(len(modhh) == (len(modhh_match) + len(modhh_added)))\n",
    "print(len(modhh_match), len(modhh_added))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keycols = ['income', 'race_id', 'age_of_head','cars', 'county_id', 'PUMA5CE']\n",
    "\n",
    "#process key col values for better matching process\n",
    "for df in [synhh, modhh_added]: \n",
    "    df[keycols] = df[keycols].fillna(na_value)\n",
    "    df[keycols] = df[keycols].round(0)\n",
    "    df[keycols] = df[keycols].astype(int)\n",
    "    print (df[keycols].head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match synhh to additional model HHs\n",
    "modhh_added = find_matching_index(modhh_added, synhh.reset_index().set_index('serialno'), keycols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match = synhh.loc[synhh.index.isin(modhh.index)]\n",
    "modhh.loc[modhh_match.index, 'serialno'] = synhh['serialno']\n",
    "modhh.loc[modhh_added.index, 'serialno'] = modhh_added['serialno']\n",
    "modhh.loc[modhh.serialno == -9] #verify if there's still added HHs with missing serialno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read HHT from 2015 PUMS dataset and attach them to model HHs\n",
    "pumshhs = pd.read_csv(os.path.join(infolder, pums_hhs), usecols=['SERIALNO'] + newhh_vars)\n",
    "modhh = pd.merge(modhh.reset_index(), pumshhs, left_on='serialno', right_on='SERIALNO', \n",
    "                                                                    how='left').set_index('household_id')\n",
    "modhh.drop(['income', 'workers'], axis = 1, inplace = True) # drop income and workers for alternatives in ABM\n",
    "print('save draft HHs to ' + os.path.join(outfolder, outhhs.replace('.csv', '_raw.csv')))\n",
    "modhh.to_csv(os.path.join(outfolder, outhhs.replace('.csv', '_raw.csv')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match PUMS samples for additional persons in model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add extra variables from PUMS data to model persons\n",
    "pumspps = pd.read_csv(os.path.join(infolder, pums_pps), usecols=['SERIALNO', 'SPORDER'] + newperson_vars)\n",
    "\n",
    "modpp = stm['persons']\n",
    "modpp_cols = modpp.columns\n",
    "modpp = pd.merge(modpp.reset_index(), modhh[['serialno', 'county_id']], left_on='household_id',                                            right_index=True, how='left').set_index('person_id')  # join new serialno\n",
    "modpp = pd.merge(modpp.reset_index(), pumspps, left_on=['serialno', 'member_id'], \n",
    "                    right_on=['SERIALNO', 'SPORDER'], how='left').set_index('person_id') #join new variables\n",
    "modpp.fillna(na_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modpp_added = modpp.loc[modpp.SERIALNO == -9] #persons without proper HH id after joining(new person only in model inputs) \n",
    "modpp_match = modpp.loc[modpp.SERIALNO != -9 ] #persons in original synthesis\n",
    "assert(len(modpp) == (len(modpp_match) + len(modpp_added)))\n",
    "print(len(modpp_match), len(modpp_added))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keycols = ['county_id', 'worker', 'sex',  'race_id', 'age']\n",
    "newid = modpp_added.index.name + '_add'\n",
    "modpp_added.index.name = newid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional person will find matches from existing person records\n",
    "modpp_added = find_matching_index(modpp_added, modpp_match, keycols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining personal variables to additional persons using matched IDs\n",
    "modpp_added = modpp_added.reset_index().set_index('person_id')\n",
    "modpp_added[newperson_vars] = modpp_match[newperson_vars]\n",
    "modpp_added = modpp_added.set_index(newid)\n",
    "modpp.loc[modpp_added.index, newperson_vars] = modpp_added[newperson_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix duplicated member_id\n",
    "modpp = modpp.reset_index()\n",
    "modpp = modpp.sort_values(by=['household_id', 'member_id', 'person_id']) #sorting by existing ids\n",
    "modpp['member_id'] = modpp.groupby('household_id').cumcount() + 1\n",
    "modpp = modpp.set_index('person_id')\n",
    "\n",
    "#fix duplicated partner records, update relate 1 to 10\n",
    "modpp_relp = modpp.loc[(modpp.relate==1) & (modpp.duplicated(['household_id', 'relate']))].index \n",
    "modpp.loc[modpp_relp, 'relate'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('save draft persons to ' + os.path.join(outfolder, outpersons.replace('.csv', '_raw.csv')))\n",
    "modpp.to_csv(os.path.join(outfolder, outpersons.replace('.csv', '_raw.csv')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Match PUMS to group quarter population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join county and PUMA to GQ pop\n",
    "modgq = pd.merge(stm['/group_quarters'], bldgeos, left_on = 'building_id', right_index=True, how='left')\n",
    "print(modgq.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('existing GQ types:', modgq.gq_code.unique())\n",
    "# 601 MILITARY, NOT PRESENT IN THIS DATASET\n",
    "# 401\toif\tOther Institutional\n",
    "# 501\tcsh\tCollege/Student Housing\n",
    "# 701\tonf\tOther NonInstitutional\n",
    "# 789\tHL\tHomeless Population\n",
    "\n",
    "modgq = modgq.loc[modgq.gq_code >= 501] #ABM only looks at noninstitutional GQ\n",
    "modgq['TYPE'] = 3  #for GQ HH type\n",
    "modgq.rename(columns={'PUMA5CE':'PUMA'}, inplace=True)\n",
    "modgq['PUMA']= modgq['PUMA'].fillna(na_value).astype(int)\n",
    "#modgq with TYPE, county_id, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pumshhs = pd.read_csv('2015_synthpop_inputs/ss15hmi.csv', usecols=['SERIALNO', 'TYPE','NP', 'PUMA00','PUMA10'])\n",
    "\n",
    "#2. PUMA 2000 to 2010 look up (one on one)\n",
    "puma_00_10 = pd.read_excel('PUMA2000_PUMA2010_crosswalk.xls')[['State10','PUMA00', 'PUMA10', 'pPUMA00_Pop10']]\n",
    "puma_00_10 = puma_00_10.loc[puma_00_10.State10 == 26].sort_values(['PUMA00', 'pPUMA00_Pop10'], ascending=False)\n",
    "puma_00_10.drop_duplicates(subset ='PUMA00', keep='first', inplace= True)\n",
    "puma_00_10= puma_00_10.set_index('PUMA00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get PUMA id, filter by GQ pop and valid PUMAs\n",
    "pumspps = pd.read_csv(os.path.join(infolder, pums_pps), usecols=['SERIALNO','SPORDER', 'RELP', 'AGEP', 'RAC1P', 'HISP','SEX', 'SCHG', 'WKHP', 'WKW', 'ESR','MIL', 'PINCP', 'PUMA00','PUMA10'])\n",
    "\n",
    "pumspps = pumspps.set_index('PUMA00')\n",
    "pumspps.update(puma_00_10[['PUMA10']]) #use lookup table to update PUMA10\n",
    "pumspps =  pumspps.rename(columns={'PUMA10': 'PUMA'}).reset_index()\n",
    "pumspps = pumspps.loc[pumspps.RELP.isin([16,17]) & pumspps.PUMA.isin(modgq.PUMA.unique())]\n",
    "pumspps = pumspps.set_index('SERIALNO')\n",
    "\n",
    "# prepare matching variables for PUMS samples\n",
    "pumspps['TYPE'] = 3\n",
    "pumspps.loc[pumspps.RELP ==16, 'TYPE'] = 2\n",
    "\n",
    "pumspps['race_id'] = pumspps.RAC1P \n",
    "pumspps.loc[pumspps.RAC1P > 2, 'race_id'] = 4\n",
    "pumspps.loc[pumspps.HISP > 1, 'race_id'] = 3\n",
    "\n",
    "pumspps['age'] = pumspps.AGEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match PUMS GQ records to model GQ\n",
    "\n",
    "modgq = find_matching_index(modgq, pumspps, ['TYPE', 'race_id', 'age', 'PUMA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modgq = pd.merge(modgq.reset_index(), pumspps, left_on = 'SERIALNO', right_index = True, how = 'left',                                                      suffixes = ('', '_y'))\n",
    "\n",
    "modgq.rename(columns = {\"RELP\": \"relate\", \"SEX\":\"sex\", \"SPORDER\": \"member_id\"}, inplace = True)\n",
    "\n",
    "modgq['person_id'] = range(2_000_000_000, 2_000_000_000 + len(modgq))\n",
    "modgq['household_id'] = modgq['person_id']\n",
    "modgq = modgq.set_index('person_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export GQ persons\n",
    "print('save draft GQ persons to ' + os.path.join(outfolder, outgq.replace('.csv', '_raw.csv')))\n",
    "modgq.to_csv(os.path.join(outfolder, outgq.replace('.csv', '_raw.csv')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process group quarter households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covnert GQ persons to GQ HHs \n",
    "pumshhs = pd.read_csv(os.path.join(infolder, pums_hhs), usecols=['SERIALNO','VEH', 'NP','NOC'] + newhh_vars)\n",
    "pumshhs = pumshhs.loc[pumshhs.TYPE > 1]\n",
    "modgq_hhs = pd.merge(modgq, pumshhs, left_on = 'SERIALNO', right_on = 'SERIALNO', how = 'left', suffixes = ('', '_y') )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename variables\n",
    "modgq_hhs.rename(columns = {'age':'age_of_head', \n",
    "                            'VEH': 'cars', \n",
    "                            'NOC': 'children',\n",
    "                            'NP': 'persons'}, inplace = True)\n",
    "modgq_hhs = modgq_hhs.set_index('household_id')  \n",
    "modgq_hhs['HHT'] = 0 #based on RSG suggestion\n",
    "modgq_hhs['HINCP'] = modgq_hhs['PINCP'] \n",
    "modgq_hhs.drop('PINCP', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('save draft GQ HHs to ' + os.path.join(outfolder, outgq_hhs.replace('.csv', '_raw.csv')))\n",
    "modgq_hhs.to_csv(os.path.join(outfolder, outgq_hhs.replace('.csv', '_raw.csv')))\n",
    "#list(set(stm['households'].columns) - set(['income', 'workers'])) + newhh_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine household and GQ records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select needed variables for final outputs\n",
    "hset = list(set(stm['households'].columns) - set(['income', 'workers'])) + newhh_vars\n",
    "pset = list(set(stm['persons'].columns) - set(['worker'])) + newperson_vars\n",
    "\n",
    "#final households and persons \n",
    "final_hhs = pd.concat([modhh[hset], modgq_hhs[hset]]).fillna(-9)\n",
    "final_pps = pd.concat([modpp[pset], modgq[pset]]).fillna(-9)\n",
    "\n",
    "print('save final HHs to ' + os.path.join(outfolder, outhhs))\n",
    "final_hhs.to_csv(os.path.join(outfolder, outhhs))\n",
    "print('save final Persons to ' + os.path.join(outfolder, outpersons))\n",
    "final_pps.to_csv(os.path.join(outfolder, outpersons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verification of data\n",
    "# 1) any NA values\n",
    "print(final_hhs.loc[final_hhs.isnull().any(axis=1)])\n",
    "print(final_pps.loc[final_pps.isnull().any(axis=1)])\n",
    "\n",
    "#2) member id\n",
    "print(final_pps.loc[final_pps.duplicated(['household_id', 'member_id'])])\n",
    "\n",
    "# 3) HHT values\n",
    "print(final_hhs.HHT.unique())\n",
    "\n",
    "#4) HINCP for GQ\n",
    "print(final_hhs.loc[(final_hhs.HHT==0 ) & (final_hhs.HINCP<0 )].HINCP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (optional) compile ABM variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update person and household worker with new definition ESR in [1,2,4,5] \n",
    "modpp.loc[modpp.ESR.isin([1,2,4,5]), 'worker'] = 1\n",
    "modhh['workers'] = 0 #reset the values, cannot keep them\n",
    "modhh['workers'] = modpp.groupby('household_id').worker.sum()\n",
    "\n",
    "modpp['pemploy'] = 2 #part time\n",
    "modpp.loc[modpp.age < 16, 'pemploy'] = 4  #under16\n",
    "modpp.loc[(modpp.age >= 16) & (modpp.ESR.isin([3,6])) , 'pemploy'] = 3 #not employed\n",
    "modpp.loc[(modpp.age >= 16) & (~modpp.ESR.isin([3,6])) & (modpp.WKHP >= 35) & (modpp.WKW.isin([1,2,3,4])), 'pemploy'] = 1  # full time\n",
    "\n",
    "modpp.loc[(modpp.age >= 16) & (modpp.pemploy == 1), 'pstudent'] = 3 # not attending school\n",
    "modpp.loc[(modpp.age < 16) & (modpp.pemploy == 1), 'pstudent'] = 1 # high school or lower\n",
    "modpp.loc[modpp.SCHG.isnull() & (modpp.age >= 16), 'pstudent'] = 3\n",
    "modpp.loc[modpp.SCHG.isnull() & (modpp.age < 16), 'pstudent'] = 1\n",
    "modpp.loc[(modpp.pemploy != 1) & (modpp.SCHG >= 15) & (modpp.age >= 16), 'pstudent'] = 2# college or higher\n",
    "modpp.loc[(modpp.pemploy != 1) & (modpp.SCHG >= 15) & (modpp.age < 16), 'pstudent'] = 1\n",
    "modpp.loc[(modpp.pemploy != 1) & (modpp.SCHG.isin(range(1,15))) & (modpp.age <= 19), 'pstudent'] = 1\n",
    "modpp.loc[(modpp.pemploy != 1) & (modpp.SCHG.isin(range(1,15))) & (modpp.age > 19), 'pstudent'] = 2\n",
    "\n",
    "modpp.loc[modpp.pemploy == 1, 'ptype'] = 1\n",
    "modpp.loc[(modpp.pemploy == 2) & (modpp.pstudent == 3), 'ptype'] = 2\n",
    "modpp.loc[(modpp.age >= 65) & (modpp.pemploy.isin([3,4])) & (modpp.pstudent == 3), \n",
    "            'ptype'] = 5\n",
    "modpp.loc[(modpp.age < 6) & (modpp.pemploy.isin([3,4])) & (modpp.pstudent == 3), \n",
    "            'ptype'] = 8\n",
    "modpp.loc[((modpp.age >= 6) & (modpp.age <= 64)) & (modpp.pemploy.isin([3,4])) &                           (modpp.pstudent == 3) , 'ptype'] = 4\n",
    "modpp.loc[(modpp.pemploy.isin([2, 3, 4])) & (modpp.pstudent == 2) , 'ptype'] = 3\n",
    "modpp.loc[(modpp.age < 6) & (modpp.pemploy.isin([2,3,4])) & (modpp.pstudent == 1), \n",
    "            'ptype'] = 8\n",
    "modpp.loc[(modpp.age >= 16) & (modpp.pemploy.isin([2,3,4])) & (modpp.pstudent == 1), \n",
    "            'ptype'] = 6\n",
    "modpp.loc[((modpp.age >= 6) & (modpp.age < 16)) & (modpp.pemploy.isin([2,3,4])) &                       (modpp.pstudent == 1) , 'ptype'] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSG notes on ABM data inputs\n",
    "\n",
    "# Household attributes:\n",
    "# 1.\tHworkers: Yes, this is number of workers in the household based on each member’s Employment Status Recode (ESR). ESR is defined in PUMS as follows:\n",
    "# Members with ESR as 1, 2, 4 and 5 are counted as workers\n",
    "# 2.\tHHT: Yes, this is the original PUMS field – Household/family type\n",
    "\n",
    "\n",
    "# Person Type (ptype):\n",
    "# 1.\tThe ptype code is defined using the following PUMS person-level variables:\n",
    "# a.\tESR: Employment Status Recode (ESR)\n",
    "# b.\tWKHP: Usual hours worked per week past 12 months\n",
    "# c.\tWKW: Weeks worked during past 12 months\n",
    "# d.\tSCHG: Grade level attending\n",
    "# e.\tAGEP: Age\n",
    "\n",
    "# 2.\tThe person type is derived from person’s age, employment status (pemploy) and student status (pstudent).\n",
    "# 3.\tThe employment status is derived from ESR, WKHP, WKW and Age\n",
    "# 4.\tThe student status is derived from SCHG, Age and employment status\n",
    "\n",
    "# As long as we have ESR, WKHP, WKW, SCHG and AGEP in the person file, employment status, student status and person type can be derived.\n",
    "\n",
    "# We have documented the person type coding process for ODOT. Please follow this link for a  detailed description of person type coding logic: https://github.com/RSGInc/SOABM/wiki/Person-Type-Coding-in-SOABM\n",
    "\n",
    "# https://github.com/RSGInc/SOABM/wiki/Person-Type-Coding-in-SOABM\n",
    "# PUMS variable definitions( year unkown * different from 2015 definitions see below)\n",
    "# Employment status recode ESR\n",
    "#     b .N/A (less than 16 years old)\n",
    "#     1 .Civilian employed, at work\n",
    "#     2 .Civilian employed, with a job but not at work\n",
    "#     3 .Unemployed\n",
    "#     4 .Armed forces, at work\n",
    "#     5 .Armed forces, with a job but not at work\n",
    "#     6 .Not in labor force\n",
    "\n",
    "# WKHP\n",
    "# Usual hours worked per week past 12 months\n",
    "#     bb .N/A (less than 16 years old/did not work during the past 12 months)\n",
    "#     01..98 .1 to 98 usual hours\n",
    "#     99 .99 or more usual hours\n",
    "\n",
    "# WKW\n",
    "# Weeks worked during past 12 months\n",
    "#     b .N/A (less than 16 years old/did not work during the past 12 months)\n",
    "#     1 .50 to 52 weeks\n",
    "#     2 .48 to 49 weeks\n",
    "#     3 .40 to 47 weeks\n",
    "#     4 .27 to 39 weeks\n",
    "#     5 .14 to 26 weeks\n",
    "#     6 .13 weeks or less\n",
    "\n",
    "# ========================================================\n",
    "# SCHG https://github.com/RSGInc/SOABM/wiki/Person-Type-Coding-in-SOABM\n",
    "# Grade level attending\n",
    "#     b .N/A (not attending school)\n",
    "#     1 .Nursery school/preschool\n",
    "#     2 .Kindergarten\n",
    "#     3 .Grade 1 to grade 4\n",
    "#     4 .Grade 5 to grade 8\n",
    "#     5 .Grade 9 to grade 12\n",
    "#     6 .College undergraduate\n",
    "#     7 .Graduate or professional school\n",
    "#     AGEP\n",
    "#     Age\n",
    "#     00 .Under 1 year\n",
    "#     01..99 .1 to 99 years (Top-coded***)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SCHG (2015 PUMS variable codes, SEMCOG model base year data)\n",
    "# Grade level attending\n",
    "#     bb .N/A (not attending school)\n",
    "#     01 .Nursery school/preschool\n",
    "#     02 .Kindergarten\n",
    "#     03 .Grade 1\n",
    "#     04 .Grade 2\n",
    "#     05 .Grade 3\n",
    "#     06 .Grade 4\n",
    "#     07 .Grade 5\n",
    "#     08 .Grade 6\n",
    "#     09 .Grade 7\n",
    "#     10 .Grade 8\n",
    "#     11 .Grade 9\n",
    "#     12 .Grade 10\n",
    "#     13 .Grade 11\n",
    "#     14 .Grade 12\n",
    "#     15 .College undergraduate years (freshman to senior)\n",
    "#     16 .Graduate or professional school beyond a bachelor's degree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python37464bitbaseconda6f9e6f4ac8a84988b167991f607929ce",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}