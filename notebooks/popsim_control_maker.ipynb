{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate control totals needed by populationsim(RSG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from census import Census\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACS5_downloader:\n",
    "\n",
    "    def __init__(self, census_reader, states, counties = None, tract_ids = None, blockgroup_ids = None):\n",
    "        self.state = states\n",
    "        self.counties = counties\n",
    "        self.tracts = tract_ids\n",
    "        self.blockgroups = blockgroup_ids \n",
    "        self.cread = census_reader\n",
    "        self.fips_lookup()\n",
    "    \n",
    "    def fips_lookup(self):\n",
    "        fips_table = pd.read_csv(\n",
    "                \"https://www2.census.gov/geo/docs/reference/codes/files/national_county.txt\",\n",
    "                header=None, names=['state','state.fips', 'county.fips', 'county' ,'type'], dtype=str)\n",
    "        if self.counties:\n",
    "            if (self.counties != '*'):\n",
    "                self.counties = fips_table.loc[(fips_table.state.isin(self.state)) & \n",
    "                            (fips_table.county.isin(self.counties))]['county.fips'].unique()\n",
    "                self.counties = ','.join(self.counties)\n",
    "        if self.state != '*':\n",
    "            self.state = fips_table.loc[fips_table.state.isin(self.state\n",
    "                                    )]['state.fips'].unique()\n",
    "            self.state = ','.join(self.state)\n",
    "\n",
    "    def state_download(self, vars):\n",
    "        return self.cread.acs5.get(vars, geo={'for': 'state:{}'.format(self.state)})\n",
    "\n",
    "    def county_download(self, vars):\n",
    "        return self.cread.acs5.get(vars, geo={'for': 'county:{}'.format(self.counties), \n",
    "                                        'in': 'state:{}'.format(self.state)})\n",
    "\n",
    "    def tract_download(self, vars):\n",
    "        return self.cread.acs5.get(vars, geo={'for': 'tract:{}'.format(self.tracts), \n",
    "                                    'in': 'state:{} county:{}'.format(self.state, self.counties)})\n",
    "\n",
    "    def blockgroup_download(self, vars):\n",
    "        clst = self.counties.split(',')\n",
    "        cm = []\n",
    "        for cn in clst:\n",
    "            cm += self.cread.acs5.get(vars, geo={'for': 'block group:{}'.format(self.blockgroups), \n",
    "                                'in': 'state:{} county:{} tract:{}'.format(self.state,cn, self.tracts)}) \n",
    "        return cm\n",
    "    \n",
    "    def download(self, variables):\n",
    "        dfm = pd.DataFrame()\n",
    "        if not(self.counties):\n",
    "            downv = self.state_download(variables)\n",
    "        elif not(self.tracts):\n",
    "            downv = self.county_download(variables)\n",
    "        elif not(self.blockgroups):\n",
    "            downv = self.tract_download(variables)\n",
    "        else:\n",
    "            downv = self.blockgroup_download(variables)\n",
    "        dfm = pd.DataFrame.from_dict(downv)\n",
    "\n",
    "        return dfm\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, counties = ['MI'], ['Oakland County', 'Washtenaw County']\n",
    "c = Census('add_your_key', year=2017) # explicit\n",
    "geo_cross_csv = \"../data/sem_geo_cross_walk.csv\"\n",
    "control_csv = \"../preprocess/controls_pre.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list Census marginal variables from controls_pre table (same as \"controls\" table with additional \"acs_variables\" field )\n",
    "# \"acs_variables\" field contains evaluation expressions, including variables from Census API and operations\n",
    "dfc = pd.read_csv(control_csv)\n",
    "dic_margs = {}\n",
    "for geo, dfgeo in dfc.groupby('geography'):  \n",
    "    full_vars= list(set(re.findall(r'B[0-9]{5}[A-Z]{0,1}_[0-9]{3}E', \n",
    "                    str(list(dfgeo.acs_variables)))))\n",
    "    if geo == 'BLKGRP':\n",
    "        ac5 = ACS5_downloader(c, state, counties, \"*\", \"*\")\n",
    "        geo_cols = ['state', 'county', 'tract', 'block group']\n",
    "    elif geo == 'TRACT':\n",
    "        ac5 = ACS5_downloader(c, state, counties, \"*\")\n",
    "        geo_cols = ['state', 'county', 'tract']\n",
    "\n",
    "    dic_margs[geo] = ac5.download(full_vars).set_index(geo_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile Census marginals to popsim control variables\n",
    "for geo, dfg in dfc.groupby('geography'):\n",
    "    for ind, r in dfg.iterrows():\n",
    "        print(r['acs_variables'])\n",
    "        dic_margs[geo] = dic_margs[geo].astype(float).fillna(0)\n",
    "        dic_margs[geo][r['control_field']] = dic_margs[geo].eval(r['acs_variables'].replace('\"', ''))\n",
    "    dic_margs[geo] = dic_margs[geo][list(dfg.control_field)] #keep only control fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add unique geoids and PUMA \n",
    "for geo, dfm in dic_margs.items():\n",
    "\n",
    "    dfcross = pd.read_csv(geo_cross_csv, dtype = str)\n",
    "    if dfm.index.nlevels == 3:\n",
    "        dfm['TRACTID'] = ['{}{}{}'.format(l1.zfill(2),l2.zfill(3),l3.zfill(6)) \n",
    "                                for l1, l2, l3 in dfm.index]\n",
    "        dfm = pd.merge(dfm.reset_index(), dfcross[['TRACTID','PUMA']], on = 'TRACTID', how = 'left')\n",
    "\n",
    "    elif dfm.index.nlevels == 4:\n",
    "        dfm['BLKGRPID'] = ['{}{}{}{}'.format(l1.zfill(2),l2.zfill(3),l3.zfill(6), l4) \n",
    "                                for l1, l2, l3, l4 in dfm.index]\n",
    "        dfm = pd.merge(dfm.reset_index(), dfcross[['BLKGRPID','PUMA']], on = 'BLKGRPID', how = 'left')    \n",
    "    dfm.columns = [c.upper() for c in dfm.columns]\n",
    "    dfm.to_csv('{}_control_totals_{}.csv'.format('_'.join([c[:3].lower() for c in counties]), geo.lower()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}